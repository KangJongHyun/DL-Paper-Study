# DL-Paper-Study

# ${\textsf{\color{purple}Attention is All You Need}}$

**Author**   
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin  

지배적으로 많이 사용하고 있는 Sequence 변환 모델은 인코더와 디코더를 포함한 RNN 혹은 CNN에 기반하고 있다. 현재(2017년) 좋은 성능을 보이는 모델은 **Attention** 메커니즘을 통해 **인코더와 디코더**를 연결한다. 

🤑 **인코더와 디코더, Attention 메커니즘이란?** 🤑  
참고 : https://glee1228.tistory.com/3  
Attention Mechanism : 

